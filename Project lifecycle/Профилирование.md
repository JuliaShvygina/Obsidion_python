---
aliases: [профилирование БД, профилирование кода]
---
```py

```

В программной инженерии профилирование - это форма динамического анализа программ, которая измеряет, например, пространство (память) или временную сложность программы, использование определенных инструкций или частоту и продолжительность вызовов функций. Чаще всего информация профилирования служит для оптимизации программ и, более конкретно, для повышения производительности.

![](https://habrastorage.org/r/w1560/webt/2c/tv/26/2ctv26yjae88cmtvy7nnh12bomq.jpeg)

## Профилирование БД 
В принципе, решение любой задачи оптимизации (не только в контексте СУБД) начинается с профилирования, хоть этот термин и не всегда употребляется явно. Мы должны разбить задачу, вызывающую нарекания, на подзадачи и измерить, какую часть общего времени они занимают. Также полезна информация о числе выполнения каждой из подзадач. Чем больше доля подзадачи в общем времени, тем больше выигрыш от оптимизации именно этой подзадачи.

Лучше всего строить профиль для одной конкретной задачи так, чтобы измерения затрагивали только действия, необходимые для выполнения именно этой задачи.

**В каких единицах измерять ресурсы?** 
Самая осмысленная для конечного пользователя характеристика — это время отклика: сколько прошло времени «от нажатия на кнопку» до «получения результата». 
Однако с технической точки зрения **смотреть на время не всегда удобно**. Оно сильно зависит от массы внешних факторов: от наполненности кэша, от текущей загруженности сервера. Если проблема решается не на продуктивном, а на другом (тестовом) сервере с иными характеристиками, то добавляется и разница в аппаратуре, в настройках, в профиле нагрузки. 
В этом смысле может оказаться удобнее смотреть, например, на **число прочитанных и записанных страниц**. Этот показатель более стабилен и как правило отражает объем работы при выполнении запроса, поскольку основное время уходит на чтение и обработку страниц с данными. Хотя — повторимся — такой показатель не имеет смысла для конечного пользователя.

Для пользователя имеет смысл время отклика. Это означает, что в профиль, вообще говоря, должна входить не только СУБД, но и клиентская часть, и сервер приложений, и передача данных по сети. Часто проблемы с производительностью кроются именно в СУБД, поскольку один неадекватно построенный план запроса может увеличивать время на порядки. Но это не всегда так. Проблема может оказаться в том, что у клиента медленное соединение с сервером, что клиентская часть долго отрисовывает полученные данные и т. п.
К сожалению, получить такой полный профиль достаточно трудно. Для этого все компоненты информационной системы должны быть снабжены подсистемами мониторинга и трассировки, учитывающими особенности именно этой системы.

При выполнении пользователем действия, выполняется обычно не один, а несколько запросов. Как определить тот запрос, который имеет смысл оптимизировать? Для этого нужен **профиль**, детализированный до запросов.

![](https://i.imgur.com/GKVSDQ9.png)

Для получения профиля по выполняемым SQL-запросам есть два основных средства, встроенных в **PostgreSQL**: журнал сообщений сервера и статистика.

Так или иначе, среди выполненных запросов мы находим тот, который будем оптимизировать. Как работать с самим запросом? Тут тоже поможет профиль, который выдает команда EXPLAIN ANALYZE.

### Как оптимизировать запрос
**1.** Используйте конкретные имена столбцов после оператора select, вместо «*» – это позволит увеличить быстроту отработки запроса и уменьшению сетевого трафика.

**2.** Сведите к минимуму использование подзапросов.

**3.** Используйте оператор IN аккуратно, поскольку на практике он имеет низкую производительность и может быть эффективен только при использовании критериев фильтрации в подзапросе.

**4.** Соединение таблиц в запросе также является критичным: в случае, когда соединение таблиц происходит в правильном порядке, то общее число строк, необходимых к обработке, значительно сократится.

При соединении основной и уточняющей таблиц убедитесь, что первой будет основная таблица, в противном случае вы рискуете получить обработку гораздо большего числа строк, чем необходимо.

**5.** Избыточность при работе с SQL – это критичная необходимость, используйте в разделе WHERE как можно больше ограничивающих условий.

**6.** Пишите простые запросы. Больше упрощайте. Оптимизатор может не справиться со слишком сложными операторами. Кроме того, иногда выполнение нескольких простых до невозможности операторов дает лучший результат по сравнению со сложными и позволяет добиться лучшей эффективности.

**7.** Помните, что одного и того же результата можно добиться разными способами. Например, оператор MINUS выполняется гораздо быстрее, чем запросы с оператором WHERE NOT EXIST.

**8.** Используйте индексы.

## Профилирование кода
**Профилирование** — это сбор характеристик программы во время ее выполнения. При **профилировании** замеряется время выполнения и количество вызовов отдельных функций и строк в **коде** программы. При помощи этого инструмента программист может найти наиболее медленные участки **кода** и провести их оптимизацию.

Какие же характеристики работы программы можно собирать?
-   время выполнения отдельных строк кода (инструкций)
-   количество вызовов и время выполнения отдельных функций
-   дерево вызовов функций
-   «[hot spots](http://ru.wikipedia.org/wiki/%D0%A5%D0%BE%D1%82-%D1%81%D0%BF%D0%BE%D1%82_(%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5))» (участки кода, на которые приходится существенная доля исполненных инструкций)
-   загрузку CPU и потребление памяти
-   обращение к другим ресурсам компьютера (например, к файловым дескрипторам)
-   и т.д. и т.п.

##### Подходы к профилированию
Существует, по крайней мере, три подхода к профилированию:
-   метод пристального взгляда
-   ручное профилирование
-   с использованием инструментов

С **методом пристального взгляда** (и родственным ему «методом тыка») всё понятно. Просто садимся перед текстовым редактором, открываем код и думаем, где может быть проблема, пробуем починить, смотрим на результат, откатываемся. И только в редких случаях (либо при высочайшей квалификации разработчика) метод оказывается действенным.

Достоинства и недостатки этого метода:
+ не требует особых знаний и умений
– сложно оценить трудозатраты и результат

**Ручное профилирование** удобно использовать, когда есть обоснованное предположение об узких местах и требуется подтвердить или опровергнуть гипотезу. Либо если нам, в отличие от первого метода, нужно получить численные показатели результатов нашей оптимизации (например, функция выполнялась за 946 милисекунд, стала отрабатывать за 73 милисекунды, ускорили код в 13 раз).

Суть этого метода в следующем: перед выполнением спорного участка программы сохраняем в переменную текущее системное время (с точностью до микросекунд), а после заново получаем текущее время и вычитаем из него значение сохранённой переменной. Получаем (с достаточной для нас погрешностью) время выполнения анализируемого кода. Для достоверного результата повторяем N раз и берём среднее значение.

Достоинства и недостатки этого метода:
+ очень простое применение
+ ограниченно подходит для продакшена
– вставка «чужеродного» кода в проект
– использование возможно не всегда
– никакой информации о программе, кроме времени выполнения анализируемого участка
– анализ результатов может быть затруднительным

**Профилирование с помощью инструментов** помогает, когда мы (по тем или иным причинам) не знаем, отчего программа работает не так, как следует, либо когда нам лень использовать ручное профилирование и анализировать его результаты. Подробнее об инструментах в следующем разделе.



##### Какие бывают инструменты

Инструменты бывают двух видов (на самом деле вариантов классификации и терминологии гораздо больше, но мы ограничимся двумя):

-   статистический (statistical) профайлер
-   событийный (deterministic, event-based) профайлер

**Статистический профайлер**
Принцип работы статистического профайлера прост: через заданные (достаточно маленькие) промежутки времени берётся указатель на текущую выполняемую инструкцию и сохраняет эту информацию («семплы») для последующего изучения.
![](https://habrastorage.org/r/w1560/getpro/habr/post_images/8a9/6cb/bc3/8a96cbbc3a23582f4ec1f465d9b01cbc.png)
Один из недостатков статистического профайлера заключается в том, что для получения адекватной статистики работы программы нужно провести как можно большее (в идеале — бесконечное) количество измерений с как можно меньшим интервалом. Иначе некоторые вызовы вообще могут быть не проанализированы:
![](https://habrastorage.org/r/w1560/getpro/habr/post_images/d4e/a00/2b9/d4ea002b9d96438ec259b11d856f88cc.png)

Достоинства и недостатки статистического профайлера:
+ можно пускать в продакшен (влияние на анализируемую программу минимально)
– получаем далеко не всю информация о коде (фактически только «hot spots»)  
– возможно некорректное интерпретирование результата  
– требуется длительное время для сбора адекватной статистики  
– мало инструментов для анализа

**Событийный профайлер**
Событийный профайлер отслеживает все вызовы функций, возвраты, исключения и замеряет интервалы между этими событиями. Измеренное время (вместе с информацией о соответствующих участках кода и количестве вызовов) сохраняется для дальнейшего анализа.
![](https://habrastorage.org/r/w1560/getpro/habr/post_images/fd3/9ee/478/fd39ee4789da3cfc81e2cedf859e78de.png)

Самый важный недостаток таких профайлеров прямо следует из принципа их работы: поскольку мы вмешиваемся в анализируемую программу **на каждом шагу**, процесс её выполнения может (и будет) сильно отличаться от «обычных» условий работы (прям как в квантовой механике). Так, например, в некоторых случаях возможно замедление работы программы в два и более раз.
И тем не менее плюсы перевешивают минусы, иначе не было бы такого огромного разнообразия различных инструментов. Просмотр результатов в удобном интерфейсе с возможностью анализа времени выполнения и количества вызовов каждой строки программы многого стоят, граф вызовов помогает обнаружить недостатки в используемых алгоритмах.

Достоинства и недостатки событийных профайлеров:  
+ не требуется изменения кода  
+ получаем всю информаци о работе программы  
+ огромное количество инструментов  
– в некоторых случаях профайлер меняет поведение программы  
– очень медленно  
– практически непригодно для продакшена

#### Инструменты
 
Стандартные библиотеки Python поражают своим разнообразием. В них, кажется, есть всё, что только может понадобится разработчику, и профайлеры не исключение. На самом деле их целых три «из коробки»:  

-   **cProfile** — относительно новый (с версии 2.5) модуль, написанный на C и оттого быстрый
-   **profile** — нативная реализация профайлера (написан на чистом питоне), медленный, и поэтому не рекомендуется к использованию
-   **hotshot** — экспериментальный модуль на си, очень быстрый, но больше не поддерживается и в любой момент может быть удалён из стандартных библиотек


### Как оптимизировать код

_Оптимизация — это модификация системы для улучшения её эффективности._

Важно чётко понимать, что именно нас не устраивает в работе программы и каких целей мы хотим достичь, но это не значит, что профилированием и последующей оптимизацией нужно заниматься тогда, когда всё начинает тормозить. Хороший программист всегда знает, как себя чувствует написанная им программа и прогнозирует её работоспособность в критических ситуациях (таких, как хабраэффект).

Хочу заметить ещё один немаловажный момент: часто оптимизация сопровождается значительным ухудшением читаемости кода. По возможности, старайтесь избегать этого, а в случае, если всё-таки пришлось написать менее читаемый код в критичных местах, не поленитесь и оставьте комментарий с подробным описанием его работы.

1. Стандартные функции
![](https://media.proglib.io/posts/2020/04/17/e2a8f535d853f22c7b55f535ce423ef9.png)
В Python много работающих очень быстро реализованных на C встроенных функций. Они покрывают большинство тривиальных вычислительных операций (`abs`, `min`, `max`, `len`, `sum`).

2. Литералы вместо функций
Когда нужен пустой словарь или список, вместо `dict()` или `list()`, можно напрямую вызвать `{}` и `[]` (для пустого множества все еще нужна функция `set()`). Этот прием не обязательно ускорит ваш код, но сделает его более "[pythonic](https://stackoverflow.com/questions/25011078/what-does-pythonic-mean)".

3. Генераторы списков
Код цикла `for` можно сократить до одной-единственной строки с помощью генератора списка, выиграв при этом в скорости почти в два раза.

4. enumerate() для значения и индекса
Иногда при переборе списка нужны и значения, и их индексы. Чтобы вдвое ускорить код используйте `enumerate()` для превращения списка в пары индекс-значение:
``` python
for i, number in enumerate(a_short_list): 
	print(f'number {i} is {number}')
```

5. zip() для перебора нескольких списков

6. Комбинация set() и in
Повысить эффективность можно предварительным удалением из списка дубликатов с помощью `set`. Таким образом, мы сократим количество элементов для проверки. Кроме того, оператор `in` очень быстро работает с множествами.

7. Проверка на True
Не следует явно указывать `== True` или `is True` в условии `if`, достаточно указать имя проверяемой переменной. Это экономит ресурсы, которые использует «магическая» функция `__eq__` для сравнения значений.

8. Подсчет уникальных значений с Counter()
Если нам необходимо подсчитать количество уникальных значений в списке, более эффективный способ для решения этой задачи – использование `Counter()` из [модуля collections](https://proglib.io/p/ne-izobretat-velosiped-ili-obzor-modulya-collections-v-python-2019-12-15).

9. Цикл for внутри функции

##### Общие советы

-   Первым делом нужно писать чистый и эффективный код. Мы должны проследить, чтобы код внутри цикла не выполнял одни и те же вычисления.
-   Также важно не открывать/закрывать подключения ввода-вывода для каждой записи в коллекции.
-   Подумайте, можно ли кэшировать объекты.
-   Проверьте, что не создаете новые экземпляры объектов там, где они не нужны.
-   И, наконец, убедитесь, что код написан лаконично и не выполняет одни и те же повторяющиеся задачи со сложными вычислениями.